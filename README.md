# one_percent 

![Hits](https://hitcounter.pythonanywhere.com/count/tag.svg?url=https%3A%2F%2Fgithub.com%2Fgitlost-murali%2Fone_percent)

Becoming 1% better at everything I want. Starting from Aug 2nd, I will note my progress here _everyday_.

<p align="center">
  <img src="https://jamesclear.com/wp-content/uploads/2015/08/tiny-gains-graph-700x700.jpg" width="316" height="292"/>
</p>

### Software (& ML) Engineering
- [ ] [Dockers - `1:50:00`/`5:16:45`](https://www.youtube.com/watch?v=RSIstPUiEjY)
- [ ] [Docker For Data Scientists](https://www.youtube.com/watch?v=0qG_0CPQhpg&feature=youtu.be)
- [X] [Understanding CoRoutines- async & await. FastAPI docs](https://fastapi.tiangolo.com/async/#in-a-hurry)
- [ ] [Binder: Repo2Docker](https://zero-to-jupyterhub.readthedocs.io/en/latest/repo2docker.html)
- [X] [Basic Intro to DVC, CML and MLFlow](https://marescas.medium.com/removing-the-gap-between-development-and-production-in-machine-learning-mlops-62fd692cb297)
- [X] [Youtube: Jekyll - Static Site Generator Playlist](https://www.youtube.com/watch?v=T1itpPvFWHI&list=PLLAZ4kZ9dFpOPV5C5Ay0pHaa0RJFhcmcB&index=1)
- [ ] [Useful tools for ML Engineer](https://www.linkedin.com/posts/chiphuyen_mlops-machinelearning-datascience-activity-6751865757212262401-oF3T/)
- [ ] [CS329S Machine Learning Systems Design](https://stanford-cs329s.github.io/syllabus.html)
  - [X] [1. Understanding machine learning production](https://docs.google.com/document/d/1VuofeF5okBATz1F7HRQmOgi5Jc4bmUiHMYjRqwF-29s/edit?usp=sharing)
  - [X] [2. Intro to machine learning systems design](https://docs.google.com/document/d/15vCMf7SbDuxST9Q-rWtx8o7qHJQN2pE5urCDFTYI1zs/edit?usp=sharing)
  - [ ] [3. Data engineering](https://docs.google.com/document/d/1b9iuZiDEGVLHyMmnf6w2y1aN6yWQhAyqk3GHlpI9q6M/edit?usp=sharing)
- [ ] [The Missing Semester](https://missing.csail.mit.edu/2020/)
  - [X] [1. Course overview + the shell](https://missing.csail.mit.edu/2020/course-shell/)
  - [ ] [2. Shell Tools and Scripting](https://missing.csail.mit.edu/2020/shell-tools/)
  - [ ] [3. Editors (Vim)](https://missing.csail.mit.edu/2020/editors/)
  - [ ] [4. Data Wrangling](https://missing.csail.mit.edu/2020/data-wrangling/)
  - [ ] [5. Command-line Environment](https://missing.csail.mit.edu/2020/command-line/)
  - [ ] [6. Version Control (Git)](https://missing.csail.mit.edu/2020/version-control/)
  - [ ] [7. Debugging and Profiling](https://missing.csail.mit.edu/2020/debugging-profiling/)
  - [ ] [8. Metaprogramming](https://missing.csail.mit.edu/2020/metaprogramming/)
  - [ ] [9. Security and Cryptography](https://missing.csail.mit.edu/2020/security/)
  - [ ] [10. Potpourri](https://missing.csail.mit.edu/2020/potpourri/)
  - [ ] [11. Q&A](https://missing.csail.mit.edu/2020/qa/)
- [ ] [CI/CD pipeline]()
  - [X] [`Video:` GitHub Actions - SSH to server and Pull the latest changes](https://www.youtube.com/watch?v=gW1TDirJ5E4)
  - [X] [Implementation of GitHub Actions to my website repo for pulling the latest changes from server whenever a push is made](https://github.com/gitlost-murali/gitlost-murali.github.io/actions)
  - [ ] [`Video`: GitHub Actions & Machine Learning Workflows with Hamel Husain](https://www.youtube.com/watch?v=S-kn4mmlxFU)
- [ ] [Kubernetes]()
  - [X] [An introduction to Kubernetes.](https://www.jeremyjordan.me/kubernetes/)
  - [X] [Kubernetes Concepts Explained in 9 minutes!](https://www.youtube.com/watch?v=QJ4fODH6DXI)
  - [X] [Introduction to Microservices, Docker, and Kubernetes - `55:07/55:07`](https://www.youtube.com/watch?v=1xo-0gCVhTU)
  - [X] [you need to learn Kubernetes RIGHT NOW!!](https://www.youtube.com/watch?v=7bA0gTroJjw)
  - [X] [`Implementation`: Deploy a simple app using minikube & k8s]()
- [ ] [Kubeflow]()
  - [X] [Session on introduction to KubeFlow](https://www.youtube.com/watch?v=2yByPQ6Iv1o)
- [ ] [Learn PostgreSQL](https://www.youtube.com/watch?v=qw--VYLpxG4)
  - [ ] [Introduction - 1 hour](https://www.youtube.com/watch?v=qw--VYLpxG4)
  - [ ] [Basic Operations - 1 hour](https://www.youtube.com/watch?v=qw--VYLpxG4)
  - [ ] [More Operations - 1 hour](https://www.youtube.com/watch?v=qw--VYLpxG4)
  - [ ] [Relations - 1 hour](https://www.youtube.com/watch?v=qw--VYLpxG4)

### Structuring machine learning projects
- [ ] [End-End & open source MLOps toolkit](https://www.reddit.com/r/MachineLearning/comments/mgzvt2/d_whats_the_simplest_most_lightweight_but/?utm_medium=android_app&utm_source=share)
- [ ] [Comparison of experiment tracking tools](https://www.reddit.com/r/MachineLearning/comments/mhchee/d_comparison_of_experiment_tracking_tools/?utm_source=share&utm_medium=web2x&context=3)
- [ ] [D Ways to speed-up the deployment process?](https://www.reddit.com/r/MachineLearning/comments/m8fmmb/d_ways_to_speedup_the_deployment_process/?utm_source=share&utm_medium=web2x&context=3)
- [ ] [Towards MLOps: Technical capabilities of a Machine Learning platform](https://medium.com/prosus-ai-tech-blog/towards-mlops-technical-capabilities-of-a-machine-learning-platform-61f504e3e281)
- [ ] [PyTorch Performance Tuning Guide - Szymon Migacz, NVIDIA](https://www.youtube.com/watch?v=9mS1fIYj1So)
- [X] [Airflow DAG: Coding your first DAG for Beginners](https://www.youtube.com/watch?v=IH1-0hwFZRQ)
- [ ] [Study material to become an ML engineer](https://twitter.com/chipro/status/1315283623910805504?s=20)
- [ ] [Managing the Model Artifacts?](https://twitter.com/nlpguy_/status/1302275537881055233?s=03)
- [ ] [Getting started with Torchserve: Learn Torchserve with examples + Introducing the management dashboard](https://cceyda.github.io/blog/torchserve/streamlit/dashboard/2020/10/15/torchserve.html)
- [ ] [Launching DAGsHub integration with MLflow](https://dagshub.com/blog/launching-dagshub-integration-with-databricks-mlflow/)
- [ ] [How to deploy PyTorch Lightning models to production](https://www.cortex.dev/post/deploy-pytorch-lightning-models)
- [ ] [ML Deployment Decision Tree](https://pakodas.substack.com/p/ml-deployment-decision-tree)
- [ ] [What is ML Ops? Best Practices for DevOps for ML (Cloud Next '18)](https://www.youtube.com/watch?v=_jnhXzY1HCw&feature=youtu.be)
- [ ] [MLOps - GitHub Repo - List of Articles/Blogs](https://github.com/visenger/awesome-mlops)
- [ ] [ML Ops - DVCorg](https://www.youtube.com/watch?v=9BgIDqAzfuA&feature=youtu.be)
  - [X] [MLOps Tutorial #1: Intro to Continuous Integration for ML](https://www.youtube.com/watch?v=9BgIDqAzfuA&feature=youtu.be)
  - [X] [MLOps Tutorial #2: When data is too big for Git](https://www.youtube.com/watch?v=kZKAuShWF0s)
  - [X] [MLOps Tutorial #3: Track ML models with Git & GitHub Actions](https://www.youtube.com/watch?v=xPncjKH6SPk)
  - [X] [MLOps Tutorial #4: GitHub Actions with your own GPUs](https://www.youtube.com/watch?v=rVq-SCNyxVc)
  - [X] [DVC Explained in Five Minutes](https://www.youtube.com/watch?v=UbL7VUpv1Bs)
  - [X] [MLOps Tutorial #5: Automated Testing for Machine Learning](https://youtu.be/bSXUJRnQPPo)
  - [X] [MLOps Tutorial #6: Behavioral tests for models with GitHub Actions](https://www.youtube.com/watch?v=ZhufbyZtF78&list=PL7WG7YrwYcnDBDuCkFbcyjnZQrdskFsBz&index=6)
  - [ ] [Elle O'Brien - Adapting continuous integration and continuous delivery for ML](https://www.youtube.com/watch?v=yp0su5mOeko&feature=emb_title)
- [ ] [Blogs on ML-Production: Proper release and monitoring of machine learning systems in production.](https://madewithml.com/topics/production/)
- [ ] [Blogs on Unit testing for ML](https://madewithml.com/topics/testing/)
- [ ] [Blogs on Continuous Integration / Continuous Deployment (CI/CD)](https://madewithml.com/topics/ci-cd/)
  - [ ] [`Blog:` Continuous Machine Learning (CML) is CI/CD for ML](https://dvc.org/blog/cml-release)
- [X] [DVC Implementation: Completed setting up a project and running a pipeline](https://dvc.org/doc/start/experiments)
- [ ] [MLOps: Accelerating Data Science with DevOps - Microsoft](https://www.youtube.com/watch?v=pqppGvTJm-A)
- [X] [MLflow: An Open Platform to Simplify the Machine Learning Lifecycle](https://www.youtube.com/watch?v=859OxXrt_TI)
- [ ] [Full Stack Deep Learning Course](https://course.fullstackdeeplearning.com/)
  - [X] [1. Setting up Machine Learning Projects](https://course.fullstackdeeplearning.com/course-content/setting-up-machine-learning-projects)
  - [ ] [2. Infrastructure and Tooling](https://course.fullstackdeeplearning.com/course-content/infrastructure-and-tooling)
    - [X] [2.1 Overview : Components of a Machine Learning system?](https://course.fullstackdeeplearning.com/course-content/infrastructure-and-tooling/overview)
    - [X] [2.2 Software Engineering: Good SEngg practices for ML developers?](https://course.fullstackdeeplearning.com/course-content/infrastructure-and-tooling/software-engineering)
    - [X] [2.3 Computing and GPUs (3) - Infrastructure & Tooling](https://course.fullstackdeeplearning.com/course-content/infrastructure-and-tooling/hardware)
    - [X] [2.4 Resource Management (4) - Infrastructure & Tooling](https://www.youtube.com/watch?v=XmHRXktfwhM&feature=emb_title)
    - [X] [2.5 Frameworks & Distributed Training (5) - Infrastructure & Tooling](https://course.fullstackdeeplearning.com/course-content/infrastructure-and-tooling/frameworks-and-distributed-training)
    - [X] [2.6 Experiment Management (6)](https://course.fullstackdeeplearning.com/course-content/infrastructure-and-tooling/experiment-management)
    - [X] [2.7 Hyperparameter Tuning (7)](https://course.fullstackdeeplearning.com/course-content/infrastructure-and-tooling/hyperparameter-tuning)
    - [X] [2.8 All-in-one Solutions (8)](https://course.fullstackdeeplearning.com/course-content/infrastructure-and-tooling/all-in-one-solutions)
  - [ ] [3. Data Management](https://course.fullstackdeeplearning.com/course-content/data-management)
  - [ ] [4. Machine Learning Teams](https://course.fullstackdeeplearning.com/course-content/ml-teams)
  - [ ] [5. Training and Debugging](https://course.fullstackdeeplearning.com/course-content/training-and-debugging)
  - [ ] [6. Testing and Deployment](https://course.fullstackdeeplearning.com/course-content/testing-and-deployment)
  - [ ] [6. Testing and Deployment](https://course.fullstackdeeplearning.com/course-content/testing-and-deployment)
  - [ ] [7. Research Areas](https://course.fullstackdeeplearning.com/course-content/testing-and-deployment)
- [ ] [Full Stack Deep Learning Course - 2021](https://fullstackdeeplearning.com/spring2021/)
  - [X] [Lecture 11A -Deployment](https://www.youtube.com/watch?v=jFflwpx4iK0)
  - [X] [Lecture 11B -Monitoring](https://www.youtube.com/watch?v=NfnpPrW30Zo)
- [ ] [Organize Your Machine Learning Pipelines with Artifacts](https://app.wandb.ai/authors/artifact-workplace-safety/reports/Organize-Your-Machine-Learning-Pipelines-with-Artifacts--VmlldzoxODQwNTY)
- [ ] [How to Deploy Machine Learning Models](https://christophergs.com/machine%20learning/2019/03/17/how-to-deploy-machine-learning-models/)

### Open-Source Contribution
- [ ] [ML Collective](https://twitter.com/ml_collective)
- [ ] [Gender Bias Checklist Module](https://github.com/freemiya)
- [ ] [Redaction Module](https://github.com/freemiya)
- [ ] [Grammar Correction Module](https://github.com/freemiya)
- [ ] [T5 Tasks]()

### Data Annotation strategies
- [X] [Snorkel: Dark Data and Machine Learning - Christopher Ré](https://www.youtube.com/watch?v=yu15Nf5eJEE)
- [X] [Snorkel: Programming Training Data with Paroma Varma of Stanford University (2019)](https://www.youtube.com/watch?v=RUPbYvzSrg0)
- [ ] [Snorkel: Tweet asking Custom Snorkel Annotation Functions](https://twitter.com/yoavgo/status/1300582803319513089)
- [ ] [FAQ #1: Tips & tricks for NLP, annotation & training with Prodigy and spaCy](https://www.youtube.com/watch?v=tMAU3gLbKII)
- [ ] [TRAINING A NEW ENTITY TYPE with Prodigy – annotation powered by active learning](https://www.youtube.com/watch?v=l4scwf8KeIA&feature=youtu.be)
- [X] [Training a NAMED ENTITY RECOGNITION MODEL with Prodigy and Transfer Learning](https://www.youtube.com/watch?v=59BKHO_xBPA&feature=youtu.be)


### Up-to-date with NLP tools
- [ ] [5 NLP Libraries Everyone Should Know | by Pawan Jain | Jul, 2020 | Towards Data Science: spaCy, NLTK, Transformers, Gensim, and Stanza](https://towardsdatascience.com/5-nlp-libraries-everyone-should-know-4f13f5263908)
- [ ] [fine-tuned (distil)GPT-2 on "Amazon fine food reviews dataset".](https://twitter.com/mrm8488/status/1300822620192092160?s=03)
- [ ] [TextAttack](https://github.com/QData/TextAttack)
- [ ] [Checklist](https://github.com/marcotcr/checklist)
- [ ] [PET: Cloze Questions](https://github.com/timoschick/pet)
- [ ] [Question Generation using Google T5  @Hugginface, Text2Text , Sense2Vec and FastApi.](https://twitter.com/RenatoViolin/status/1293266821550944256?s=20)
- [ ] [The Hugging face Transformers master branch now includes a built-in pipeline for zero-shot text classification, to be included in the next release.](https://twitter.com/huggingface/status/1293240692924452864?s=20)
- [ ] [Language Interpretability Tool (LIT)](https://github.com/pair-code/lit)
- [ ] [How to Fine-Tune BERT Transformer with spaCy 3](https://walidamamou.medium.com/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647)
- [ ] [Tools & Flow for reproducible deep learning](https://twitter.com/s_scardapane/status/1389240445788643329)
- [ ] [NLP guide from AllenNLP](https://guide.allennlp.org/overview/)
- [ ] [Is there any approach to normalize words like helllllloooooo to hello?](https://www.reddit.com/r/LanguageTechnology/comments/io87i7/is_there_any_approach_to_normalize_words_like/?utm_medium=android_app&utm_source=share)
- [X] [BioBERT for Medical Domain](https://www.reddit.com/r/LanguageTechnology/comments/ip9qfz/biobert_cosine_similarity/?utm_medium=android_app&utm_source=share)
- [ ] [Codequestion: Ask coding questions directly from the terminal](https://www.reddit.com/r/MachineLearning/comments/irauuz/p_codequestion_ask_coding_questions_directly_from/?utm_medium=android_app&utm_source=share)
- [ ] [NLP models Template generation - HuggingFace](https://www.linkedin.com/posts/philipvollet_opensource-nlp-artificialintelligence-activity-6700850821002862592-zkw6/)
- [X] [DiffBot - Observations on various tasks]()
- [ ] [Argos-Translate -> Open source offline translation app written in Python. Uses OpenNMT for translations.](https://github.com/argosopentech/argos-translate)
- [ ] [Extract transliteration pairs from a parallel corpus using Moses](https://github.com/gv22ga/moses-transliteration-pair-mining.git)
- [ ] [Text-to-SQL Generation for Question Answering on Electronic Medical Records](https://github.com/wangpinggl/TREQS)
- [X] [HuggingFace NeuralCoref blog on how they are doing Coreference resolution](https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30#06e5)
- [X] [How to train a neural coreference model— Neuralcoref 2](https://medium.com/huggingface/how-to-train-a-neural-coreference-model-neuralcoref-2-7bb30c1abdfe)
- [ ] [TorchMetrics V0.2, a collection of #PyTorch metric implementations.](https://pytorch-lightning.medium.com/torchmetrics-pytorch-metrics-built-to-scale-7091b1bec919)

### Essential tools
- [X] [Talk: Camelot -> Extracting Tables from PDFs](https://www.youtube.com/watch?v=99A9Fz6uHAA)
- [ ] [Git repo: Making Language Models like BERT, ALBERTA etc good at _Sentence Representations_](https://github.com/UKPLab/sentence-transformers)
- [X] [Faker: Generates fake data for you like fake names, address etc](https://github.com/joke2k/faker)
- [X] [Label-Studio: Setup and map with a ML model](https://github.com/heartexlabs/label-studio)
- [ ] [Gradio: Quickly create customizable UI components around your TensorFlow or PyTorch models, or even arbitrary Python functions.](https://github.com/gradio-app/gradio)
- [ ] [UBIAI: Easy-to-Use Text Annotation for NLP Applications](https://ubiai.tools/)
- [ ] [Production scale, Kubernetes-native vision AI platform, with fully integrated components for model building, automated labeling, data processing and model training pipelines.](https://github.com/onepanelio/core)
- [ ] [CascadeTabNet - Cascade mask R-CNN HRNet to detect Tables](https://github.com/DevashishPrasad/CascadeTabNet)
- [ ] [Text Recognition with CRNN-CTC Network](https://app.wandb.ai/authors/text-recognition-crnn-ctc/reports/Text-Recognition-with-CRNN-CTC-Network--VmlldzoxNTI5NDI)
- [X] [VS Code (codeserver) on Google Colab / Kaggle / Anywhere](https://www.youtube.com/watch?v=7kTbM3D02jU)
- [X] [OpenRefine Lib for cleaning, managing data](https://openrefine.org/)
- [ ] [RasaLitHQ: bulk labelling with a ui from a jupyter notebook](https://github.com/RasaHQ/rasalit/blob/master/notebooks/bulk-labelling/bulk-labelling-ui.ipynb)

### Building strong ML/NLP Fundamentals
- [X] [Video: Understanding ROC Curve](https://www.youtube.com/watch?v=4jRBRDbJemM)
- [X] [Video: BackPropagation Through Time](https://www.youtube.com/watch?v=Xeb6OjnVn8g)
- [ ] [A Friendly introduction to PCA](http://peterbloem.nl/blog/pca)
- [ ] [Decision Trees Playlist](https://www.youtube.com/watch?v=3vZo0ApLz0A&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3&index=32)
  - [X] [1. Intro to Decision Trees](https://www.youtube.com/watch?v=3vZo0ApLz0A&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3&index=32)
- [ ] [The Sorcerer’s Apprentice Guide to Training LSTMs](https://www.niklasschmidinger.com/posts/2020-09-09-lstm-tricks/)
- [ ] [Are categorical variables getting lost in your random forests](https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/)
- [ ] [How to learn Gaussian Process](https://www.reddit.com/r/MachineLearning/comments/itm5wh/how_to_learn_gaussian_process_r/?utm_medium=android_app&utm_source=share)
- [ ] [CS224N](http://web.stanford.edu/class/cs224n/)
  - [X] [1. Introduction and Word Vectors](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=1)
  - [X] [2. Word Vectors and Word Senses](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=2)
  - [X] [3. Neural Networks](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=3)
  - [X] [4. Backpropagation](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=4)
  - [X] [5. Dependency Parsing](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=5)
  - [X] [6. Language Models and RNNs](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=6)
  - [X] [7. Vanishing Gradients, Fancy RNNs](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=7)
  - [X] [8. Translation, Seq2Seq, Attention](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=8)
  - [X] [9. Practical Tips for Projects](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=9)
  - [X] [10. Question Answering](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=10)
  - [X] [11. Convolutional Networks for NLP](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=11)
  - [X] [`57:00/1:15`12. Subword Models](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=12)
  - [ ] [13. Contextual Word Embeddings](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=13)
  - [ ] [14. Transformers and Self-Attention](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=14)
  - [ ] [15. Natural Language Generation](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=15)
  - [ ] [16. Coreference Resolution](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=16)
  - [ ] [17. Multitask Learning](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=17)
  - [ ] [18. Constituency Parsing, TreeRNNs](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=18)
  - [ ] [19. Bias in AI](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=19)
  - [ ] [20. Future of NLP + Deep Learning](https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&index=20)

- [ ] [Coursera NLP Specialization](https://www.coursera.org/specializations/natural-language-processing)
  - [ ] [1. Natural Language Processing with Classification and Vector Spaces](https://www.coursera.org/learn/classification-vector-spaces-in-nlp)
  - [ ] [2. Natural Language Processing with Probabilistic Models](https://www.coursera.org/learn/probabilistic-models-in-nlp)
  - [ ] [3. Natural Language Processing with Sequence Models](https://www.coursera.org/learn/sequence-models-in-nlp)
  - [ ] [4. Natural Language Processing with Attention Models](https://www.coursera.org/learn/attention-models-in-nlp)

- [ ] [Book : Speech and Language Processing - Jurafsky](https://web.stanford.edu/~jurafsky/slp3/)
  - [ ] [`22/27`Pages Chapter-2: Regular Expressions, Text Normalization, Edit Distance]()
- [ ] [Natural Language Processing - Jurafsky & Manning](https://www.youtube.com/watch?v=oWsMIW-5xUc&list=PLLssT5z_DsK8HbD2sPcUIDfQ7zmBarMYv)
- [ ] [Stanford CS229: Machine Learning (Autumn 2018)](https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU)
- [ ] [Book: Emily M Bender's book](https://twitter.com/emilymbender/status/1305938604556824577?s=20)

### Cross-lingual NER
- [ ] [`5/9` - Entity Projection via Machine-Translation for Cross-Lingual NER](https://www.aclweb.org/anthology/D19-1100v2.pdf)
- [ ] [Zero-Resource Cross-Lingual Named Entity Recognition](https://arxiv.org/pdf/1911.09812.pdf)
- [X] [`8/8` - Neural Cross-Lingual Named Entity Recognition with Minimal Resources](https://www.aclweb.org/anthology/D18-1034.pdf)
- [ ] [`4/9` - Word Alignment by Fine-tuning Embeddings on Parallel Corpora](https://arxiv.org/pdf/2101.08231.pdf)
- [ ] [UniTrans : Unifying Model Transfer and Data Transfer for Cross-Lingual Named Entity Recognition with Unlabeled Data](https://arxiv.org/pdf/2007.07683v1.pdf)
- [X] [Baseline setup of BERT variants-NER integrated with wandb](https://github.com/gitlost-murali/biobert-ner)

### Stay up-to-date in research
- [ ] [NewsLetters]()
  - [ ] [AlphaSignal.Ai: latest breakthroughs in Machine Learning](https://alphasignal.ai/)
- [ ] [Papers](https://github.com/gitlost-murali/one_percent)
  - [ ] [Entailment as Few-Shot Learner](https://arxiv.org/abs/2104.14690)
  - [X] [NLP Checklist Paper](https://arxiv.org/abs/2005.04118)
  - [ ] [`6/9` - Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach](https://arxiv.org/abs/1909.00161)
  - [X] [Let Me Choose: From Verbal Context to Font Selection](https://arxiv.org/abs/2005.01151)
  - [ ] [`6/9` - Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291)
  - [ ] [`4/8` - A Multilingual View of Unsupervised Machine Translation](https://arxiv.org/abs/2002.02955)
  - [X] [The First Cross-Script Code-Mixed Question Answering Corpus](http://personales.upv.es/prosso/resources/BanerjeeEtAl_MultiLingMine16.pdf)
  - [ ] [`9/17` - Multilingual Denoising Pre-training for Neural Machine Translation](https://arxiv.org/abs/2001.08210)
  - [ ] [Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals](https://www.nature.com/articles/s41467-020-18073-9)
  - [X] [OverView of Explicit Cross-lingual Pre-training for Unsupervised Machine Translation](https://www.aclweb.org/anthology/D19-1071.pdf)
  - [ ] [`6/8` - A unified framework for evaluating the risk of re-identification of text de-identification tools](https://pubmed.ncbi.nlm.nih.gov/27426236/)
  - [ ] [On the Cross-lingual Transferability of Monolingual Representations.](https://arxiv.org/abs/1910.11856)
  - [ ] [Prefix-tuning: Train small, continuous vectors to act as 'prompts' for different downstream tasks in GPT-2 and BART.](https://arxiv.org/abs/2101.00190)
  - [ ] [Warning sign If you are using a pretrained transformer, data augmentation doesn’t help : How Effective is Task-Agnostic Data Augmentation for Pretrained Transformers?](https://arxiv.org/abs/2010.01764)
  - [ ] [Self-training Improves Pre-training for Natural Language Understanding](https://arxiv.org/abs/2010.02194)
  - [ ] [Investigating representations of verb bias in neural language models](https://arxiv.org/abs/2010.02375)
  - [ ] [Using Multilingual Entity linking, we can automatically evaluate Machine Translation. KoBE: Knowledge-Based Machine Translation Evaluation](https://arxiv.org/abs/2009.11027)
  - [ ] [Multilevel Text Alignment with Cross-Document Attention](https://arxiv.org/abs/2010.01263)
  - [ ] [The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?](https://arxiv.org/abs/2010.05607)
  - [ ] [MAD-X : An Adapter-based Framework forMulti-task Cross-lingual Transfer](https://public.ukp.informatik.tu-darmstadt.de/MAD-X/paper.pdf)
  - [ ] [It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners](https://arxiv.org/abs/2009.07118)
  - [ ] [Utility is in the Eye of the User: A Critique of NLP Leaderboards](https://arxiv.org/abs/2009.13888)
  - [ ] [FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence](https://arxiv.org/abs/2001.07685)
  - [ ] [‘Less Than One’-Shot Learning: Learning N Classes From M<N Samples](https://arxiv.org/abs/2009.08449)
  - [ ] [Grounded Compositional Outputs for Adaptive Language Modeling](https://arxiv.org/abs/2009.11523)
  - [ ] [Plug and Play Autoencoders for Conditional Text Generation](https://arxiv.org/abs/2010.02983)
  - [ ] [Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation](https://arxiv.org/pdf/2009.09359.pdf)
  - [ ] [Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages](https://arxiv.org/pdf/2010.02353.pdf)
  - [ ] [Human Attention Maps for Text Classification: Do Humans and Neural Networks Focus on the Same Words?](https://www.aclweb.org/anthology/2020.acl-main.419)
  - [ ] [iNLTK: Natural Language Toolkit for Indic Languages](https://arxiv.org/pdf/2009.12534.pdf)
  - [ ] [Knowledge-Aware Language Model Pretraining](https://arxiv.org/abs/2007.00655)
  - [ ] [Integrating Semantic Knowledge to Tackle Zero-shot Text Classification](https://arxiv.org/pdf/1903.12626.pdf)
  - [ ] [Vokenization: a visually-supervised language model attempt](https://twitter.com/HaoTan5/status/1316785618278666241?s=20)
  - [ ] [Self-training Improves Pretraining for Natural Language Understanding](https://twitter.com/alex_conneau/status/1316773613694001152?s=20)
  - [ ] [Continual Learning and Active Learning](https://arxiv.org/abs/2009.01797)
  - [ ] [Design Challenges for Low-resource Cross-lingual Entity Linking](https://arxiv.org/abs/2005.00692)
  - [ ] [Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto-Encoders](https://www.youtube.com/watch?v=f2m6Mon0VE8)
  - [ ] [Contextualized Weak Supervision for Text Classification](https://www.aclweb.org/anthology/2020.acl-main.30)
  - [ ] [AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models](https://arxiv.org/pdf/1909.09251.pdf)
  - [ ] [Pre-training via Paraphrasing](https://arxiv.org/pdf/2006.15020.pdf)
  - [ ] [A language model you can add symbolic facts to! ](https://arxiv.org/abs/2007.00849)
  - [ ] [Perturbation sensitivity analysis to detect **unintended model biases**](https://arxiv.org/abs/1910.04210)
  - [ ] [Asking Crowdworkers to Write Entailment Examples: The Best of Bad Options](https://twitter.com/claravania/status/1316405457511231490?s=20)
  - [ ] [Big Bird: Transformers for Longer Sequences](https://arxiv.org/abs/2007.14062)
  - [ ] [The State and Fate of Linguistic Diversity and Inclusion in the NLP World](https://arxiv.org/pdf/2004.09095.pdf)
  - [ ] [A Call for More Rigor in Unsupervised Cross-lingual Learning](https://www.aclweb.org/anthology/2020.acl-main.658/)
  - [X] [`5/5` - Publicly Available Clinical BERT Embeddings](https://arxiv.org/pdf/1904.03323.pdf)
  - [ ] [`4/7` - ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission](https://arxiv.org/pdf/1904.05342.pdf)
  - [ ] [Deploying Lifelong Open-Domain Dialogue Learning](https://arxiv.org/abs/2008.08076)
  - [ ] [The Woman Worked as a Babysitter: On Biases in Language Generation](https://arxiv.org/pdf/1909.01326.pdf)
  - [ ] [Annotated Paper on __What should not be Contrastive in Contrastive learning__](https://github.com/AakashKumarNain/annotated_research_papers/)
  - [ ] [Generative Language Modeling for Automated Theorem Proving](https://arxiv.org/abs/2009.03393)
  - [ ] [Investigating Gender Bias in BERT](https://arxiv.org/abs/2009.05021)
  - [ ] [The Return of Lexical Dependencies: Neural Lexicalized PCFGs](https://arxiv.org/abs/2007.15135)
  - [ ] [Utility is in the Eye of the User: A Critique of NLP Leaderboards](https://arxiv.org/pdf/2009.13888.pdf)
  - [ ] [An Image Is Worth 16X16 Words: Transformers For Image Recognition At Scale](https://openreview.net/pdf?id=YicbFdNTTy)
  - [ ] [Compositional Explanations of Neurons](https://arxiv.org/pdf/2006.14032.pdf)
  - [ ] [Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?](https://arxiv.org/abs/2010.04119) and [its Tweet](https://twitter.com/peterbhase/status/1314600474180497409?s=03)
  - [ ] ["You are grounded!": Latent Name Artifacts in Pre-trained Language Models](https://arxiv.org/abs/2004.03012v2)
  - [ ] [Unsupervised Commonsense Question Answering with Self-Talk](https://arxiv.org/abs/2004.05483v2)
  - [ ] [Understanding Self-supervised Learning with Dual Deep Networks](https://arxiv.org/abs/2010.00578)

- [ ] [Talks/Videos](https://github.com/gitlost-murali/one_percent)
  - [X] [Ilya GPT-2 Talk](https://www.youtube.com/watch?v=T0I88NhR_9M)
  - [X] [NLP Idiots](https://www.youtube.com/watch?v=f2m6Mon0VE8)
  - [X] [Getting Started With Diffbot's Excel Add-In: Data Enrichment](https://www.youtube.com/watch?v=lbG5fl5foD8)
  - [X] [Getting Started With Diffbot's Excel Add-In: Lead Generation](https://www.youtube.com/watch?v=_G_feBvk-lY)
  - [X] [VLDB2020: The Diffbot Knowledge Graph](https://www.youtube.com/watch?v=d58BwcyTwEo)
  - [X] [Data Augmentation using PreTrained Models](https://www.youtube.com/watch?v=3N_a7LAU-pc&feature=youtu.be)
  - [X] [SpanBERT: Improving Pre-training by Representing and Predicting Spans | Research Paper Walkthrough](https://www.youtube.com/watch?v=QUP3rMrA1mk)
  - [ ] [Please Stop Doing "Explainable" ML - Cynthia Rudin](https://www.youtube.com/watch?v=I0yrJz8uc5Q)
  - [ ] [Text Data Augmentation Made Simple By Leveraging NLP Cloud APIs - Claude Coulombe](https://www.youtube.com/watch?v=rEAxxE6-wco)
  - [X] [Well-Read Students Learn Better](https://www.youtube.com/watch?v=yEhwRsuaPQs)
  - [X] [Easy Data Augmentation for Text Classification](https://www.youtube.com/watch?v=3w92peJtYNQ)
  - [X] [TextAttack: A Framework for Data Augmentation and Adversarial Training in NLP](https://youtu.be/VpLAjOQHaLU)
  - [ ] [ACL 2019 tutorial on Unsupervised Cross-lingual Representation Learning](https://tinyurl.com/xlingual)
  - [ ] [Small Language Models Are Also Few-Shot Learners](https://www.youtube.com/watch?v=UrGZCPalfoE&feature=youtu.be)
  - [X] [REALM: Retrieval-Augmented Language Model Pre-Training | NLP Journal Club](https://www.youtube.com/watch?v=mFoEig-Xi_0)
  - [X] [Knowledge Graph made simple using NLP and Transfer Learning by Suyog Swami](https://www.youtube.com/watch?v=S25CEMULDfc)
  - [X] [Building a Knowledge Graph Using Messy Real Estate Data | Cherre](https://www.youtube.com/watch?v=Bp38pYrpdSY)
  - [ ] [Linkedin's New Search Engine | DeText: A Deep Text Ranking Framework with BERT | Deep Ranking Model](https://www.youtube.com/watch?v=Dd4Rw3t5QQk&feature=emb_title)
  - [ ] [The Hardware Lottery (Paper Explained)](https://youtu.be/MQ89be_685o)
  - [ ] [Training more effective learned optimizers, and using them to train themselves (Paper Explained)](https://www.youtube.com/watch?v=3baFTP0uYOc&feature=youtu.be)

- [ ] [Podcasts]()
  - [ ] [Generating Sentiment-Preserving Fake Online Reviews Using Neural Language Models and Their Human- and Machine-based Detection](https://dataskeptic.libsyn.com/sentiment-preserving-fake-reviews) based on [Paper](https://arxiv.org/abs/1907.09177)
  - [X] [Finding Trash in Sensitive Waterways with AI - `26:00`](https://open.spotify.com/episode/2GZjam1c5QHPagdyQFW3Iw)
  - [X] [NVIDIA's Keith Strier Talks AI Nations - `30:00`](https://open.spotify.com/episode/6XVDdAUUt86zr6MNdqO2wD)

- [ ] [Blogs](https://github.com/gitlost-murali/one_percent)
  - [X] [Why You Should Do NLP Beyond English](https://ruder.io/nlp-beyond-english/)
  - [X] [Simple Ways to Tackle Class Imbalance](https://app.wandb.ai/authors/class-imbalance/reports/Simple-Ways-to-Tackle-Class-Imbalance--VmlldzoxODA3NTk)
  - [X] [Custom NLP Approaches to Data Anonymization](https://towardsdatascience.com/nlp-approaches-to-data-anonymization-1fb5bde6b929)
  - [X] [NLP Keeps Stealing From CV 👨🏻‍🎤 Why NLP engineers shouldn’t stop learning CV](https://pakodas.substack.com/p/nlp-keeps-stealing-from-cv-)
  - [X] [Introducing Label Studio, a swiss army knife of data labeling](https://towardsdatascience.com/introducing-label-studio-a-swiss-army-knife-of-data-labeling-140c1be92881#3907-fd502dc24c8d)
  - [X] [How to Skim Through Research Paper](https://twitter.com/hardmaru/status/1305758751798910976?s=03)
  - [X] [TaBERT: A new model for understanding queries over tabular data](https://ai.facebook.com/blog/tabert-a-new-model-for-understanding-queries-over-tabular-data/)
  - [X] [Adaptive Risk Minimization: Adapting to new test distribution in production](https://ai.stanford.edu/blog/adaptive-risk-minimization/)
  - [X] [How we sped up transformer inference 100x for 🤗 API customers](https://huggingface.co/blog/accelerated-inference)
  - [X] [Attention Is Not All You Need: Google & EPFL Study Reveals Huge Inductive Biases in Self-Attention Architectures](https://medium.com/syncedreview/attention-is-not-all-you-need-google-epfl-study-reveals-huge-inductive-biases-in-self-attention-fa3cdd060abe)
  - [ ] [Unsupervised NER using BERT](https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a)
  - [ ] [Maximizing BERT model performance](https://towardsdatascience.com/maximizing-bert-model-performance-539c762132ab)
  - [ ] [Comprehensive Language Model Fine Tuning, Part 1: 🤗 Datasets library - Normalizing](https://www.ntentional.com/nlp/datasets/tokenization/processing/2020/10/09/comprehensive-datasets.html)
  - [ ] [MixUp Augmentation](https://towardsdatascience.com/2-reasons-to-use-mixup-when-training-yor-deep-learning-models-58728f15c559)
  - [ ] [Paper -> Adjective ordering is universal across languages](https://twitter.com/junyenle/status/1316429411193847812?s=20)
  - [ ] [Should you deploy and use Semi-Supervised Learning in production? -> From Research to Production with Deep Semi-Supervised Learning](https://towardsdatascience.com/from-research-to-production-with-deep-semi-supervised-learning-7caaedc39093)
  - [ ] [On the Ability and Limitations of Transformers to Recognize Formal Languages](https://twitter.com/satwik1729/status/1315575680885637120?s=20)
  - [X] [WTF is a knowledge graph?](https://hackernoon.com/wtf-is-a-knowledge-graph-a16603a1a25f)
  - [X] [Introduction to Knowledge Graphs and their Applications](https://medium.com/analytics-vidhya/introduction-to-knowledge-graphs-and-their-applications-fb5b12da2a8b)
  - [ ] [Challenges of Knowledge Graphs](https://medium.com/@sderymail/challenges-of-knowledge-graph-part-1-d9ffe9e35214)
  - [ ] [Building a knowledge graph in python from scratch](https://rabinpoudyal.medium.com/building-a-knowledge-graph-in-python-from-scratch-6347199e060f)
  - [ ] [Measuring dataset similarity using optimal transport](https://www.microsoft.com/en-us/research/blog/measuring-dataset-similarity-using-optimal-transport/?OCID=msr_blog_otdd_tw)
  - [ ] [The Best NLP Papers From ICLR 2020](https://www.topbots.com/best-nlp-papers-from-iclr-2020/)
  - [X] [What is XLNet and why it outperforms BERT -> Basic knowledge of XLNet to understand the difference between XLNet and BERT intuitively](https://towardsdatascience.com/what-is-xlnet-and-why-it-outperforms-bert-8d8fce710335)
  - [X] [Paper Dissected: “XLNet: Generalized Autoregressive Pretraining for Language Understanding” Explained](https://mlexplained.com/2019/06/30/paper-dissected-xlnet-generalized-autoregressive-pretraining-for-language-understanding-explained/)
  - [X] [Understand the Two-Stream Self-Attention in XLNet intuitively](https://towardsdatascience.com/what-is-two-stream-self-attention-in-xlnet-ebfe013a0cf3)
  - [ ] [Is Hopfield Networks All You Need?](https://analyticsindiamag.com/modern-hopfield-network-transformers-attention/)
  - [ ] [Hopfield Networks is All You Need](https://ml-jku.github.io/hopfield-layers/?s=03)
  - [ ] [Challenges in going from POCs to Production-Ready ML system](https://twitter.com/full_stack_dl/status/1313129048420229120?s=03)
  - [ ] [CodeMix: A Semi-supervised Approach to Generate the Code-mixed Text using Pre-trained Encoder and Transfer Learning](https://www.linkedin.com/posts/asif-ekbal-3b8a4517_coling-and-emnlp-accepted-the-following-papers-activity-6721392502500294656-nDvf)
  - [ ] [iNLTK Feature: CodeMix for Indic Languages: About generating synthetic code-mix data](https://www.linkedin.com/posts/gaurav-arora-23593220_nlp-codemixed-deeplearning-activity-6721048175848783872-RndX/)
  - [ ] [Transformers-based Encoder-Decoder Models](https://huggingface.co/blog/encoder-decoder)
  - [ ] [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate)
  - [ ] [GLUCOSE: GeneraLized & COntextualized Story Explanations](https://twitter.com/nasrinmmm/status/1305958005683490823?s=20)
  - [ ] [PyCon India 2020 Interesting Talks](https://twitter.com/DrElleOBrien/status/1312104309669027841?s=20)
  - [ ] [Under the Hood of Sequence Models](https://madewithml.com/projects/2449/under-the-hood-of-sequence-models/)
  - [X] [How are spaCy models trained in the background?](https://www.reddit.com/r/LanguageTechnology/comments/imkl7s/how_are_spacy_models_trained_in_the_background/?utm_medium=android_app&utm_source=share)
  - [ ] [Tutorial: Training on larger batches with less memory in AllenNLP](https://medium.com/ai2-blog/tutorial-training-on-larger-batches-with-less-memory-in-allennlp-1cd2047d92ad)
  - [ ] [Knowledge Distillation](https://nervanasystems.github.io/distiller/knowledge_distillation.html#knowledge-distillation)
  - [ ] [Achieving Human Parity on Automatic Chinese to English News Translation](https://www.microsoft.com/en-us/research/publication/achieving-human-parity-on-automatic-chinese-to-english-news-translation/)
  - [ ] [Introducing UBIAI: Easy-to-Use Text Annotation for NLP Applications](https://medium.com/@walidamamou/introducing-ubiai-easy-to-use-text-annotation-for-nlp-applications-74a2401fa725)
  - [ ] [Developments in NLP from RNNs(1985) to Big Bird(2020).](https://eugeneyan.com/writing/nlp-supervised-learning-survey/)
  - [ ] [Hugging Face - 🤗Hugging Face Newsletter Issue #2]()
  - [ ] [Few-Shot Learning with fast.ai](https://towardsdatascience.com/few-shot-learning-with-fast-ai-81c66064e372)
  - [X] [Zero-Shot Learning in Modern NLP](https://joeddav.github.io/blog/2020/05/29/ZSL.html)
  - [ ] [Topic Modeling! Leveraging BERT, and TF-IDF to create easily interpretable topics - README of the repo](https://github.com/MaartenGr/BERTopic)
  - [ ] [Better Language Models and Their Implications](https://openai.com/blog/better-language-models/)
  - [ ] [Practical AI: Using NLP word embeddings to solve localization](https://madewithml.com/projects/2251/practical-ai-using-nlp-word-embeddings-to-solve-localization/)
  - [ ] [Introduction to Graph Neural Networks with GatedGCN](https://app.wandb.ai/yashkotadia/gatedgcn-pattern/reports/Introduction-to-Graph-Neural-Networks-with-GatedGCN--VmlldzoyMDg4MjA)
  - [ ] [Learning from imbalanced data](https://www.jeremyjordan.me/imbalanced-data/)
  - [ ] [Accelerate your Hyperparameter Optimization with PyTorch’s Ecosystem Tools](https://medium.com/pytorch/accelerate-your-hyperparameter-optimization-with-pytorchs-ecosystem-tools-bc17001b9a49)
  - [ ] [Which Optimizer should I use for my Machine Learning Project?](https://www.whattolabel.com/post/which-optimizer-should-i-use-for-my-machine-learning-project)
  - [ ] [Tempering Expectations for GPT-3 and OpenAI’s API](https://minimaxir.com/2020/07/gpt3-expectations/)
  - [ ] [Effective testing for machine learning systems](https://www.jeremyjordan.me/testing-ml/)
  - [ ] [Deep Reinforcement Learning: Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/)
  - [ ] [Finding Cross-lingual Syntax](https://ai.stanford.edu/blog/finding-crosslingual-syntax/)
  - [X] [Get rid of AI Saviorism](https://www.shreya-shankar.com/ai-saviorism/)
  - [ ] [An A.I. Training Tool Has Been Passing Its Bias to Algorithms for Almost Two Decades](https://onezero.medium.com/amp/p/2967ffdd1035?__twitter_impression=true&s=03)
  - [X] [REALM: Integrating Retrieval into Language Representation Models](https://ai.googleblog.com/2020/08/realm-integrating-retrieval-into.html)
  - [X] [Amazon’s open-source tools make embedding knowledge graphs much more efficient](https://www.amazon.science/blog/amazons-open-source-tools-make-embedding-knowledge-graphs-much-more-efficient)
  - [ ] [Amazon Web Services open-sources biological knowledge graph to fight COVID-19](https://www.amazon.science/blog/amazon-web-services-open-sources-biological-knowledge-graph-to-fight-covid-19)
  - [ ] [Intro to Adversarial Examples](https://app.wandb.ai/authors/adv-dl/reports/An-Introduction-to-Adversarial-Examples-in-Deep-Learning--VmlldzoyMTQwODM?s=03)
  - [ ] [Adversarial Attack and Defense on Neural Networks in PyTorch](https://towardsdatascience.com/adversarial-attack-and-defense-on-neural-networks-in-pytorch-82b5bcd9171)


### General-Courses (Interesting but not immediate)
- [ ] [FastAI - Course-v4](https://course.fast.ai/)
  - [X] [L1: Intro to fastAI- `1:22:30`](https://course.fast.ai/videos/?lesson=1)
- [ ] [Justin Johnson - Deep Learning for Computer Vision](https://www.youtube.com/watch?v=dJYGatp4SvA&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r&index=2&t=0s)
- [ ] [NYU Deep learning course - Interesting!!!!!](https://www.youtube.com/watch?v=kwPWpVverkw)
   - [X] [Lecture-1: History, motivation and evolution of DL](https://www.youtube.com/watch?v=0bMe_vCZo30&list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq)
- [ ] [Dive into Deep Learning](https://d2l.ai/)
- [ ] [ETH-Zurich Machine Learning](https://las.inf.ethz.ch/teaching/introml-s20)
- [ ] [Tweet mentioning a lot of cool apps](https://twitter.com/sannykimchi/status/1294285085672431618?s=20)
- [ ] [Tweet mentioning a lot of traditional & popular courses](https://twitter.com/chipro/status/1157772112876060672?s=20)
- [ ] [Why Does Deep Learning Perform Deep Learning - MSR AI Seminar 08/11/2020](https://www.youtube.com/watch?v=sd2o1PbqixI&feature=youtu.be)
- [ ] [NLP Course -> Interactive examples, intuitive explanations, lovely graphics.](https://lena-voita.github.io/nlp_course.html)
- [ ] [Slither Into Python](https://www.slitherintopython.com/index.html)
- [ ] [Advanced Computer Vision](https://www.youtube.com/playlist?list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39)
- [ ] [Deep Learning for Computer Vision](https://www.youtube.com/playlist?list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)
- [ ] [Amazing line-up of tutorials on self-supervised, semi-supervised & weakly-supervised learning.](https://nvlabs.github.io/eccv2020-limited-labels-data-tutorial/)
- [ ] [Intro to Causal Learning](https://www.bradyneal.com/causal-inference-course)
- [ ] [Curated list of tutorials, projects, libraries, videos, papers, books and anything related to the incredible PyTorch.](https://github.com/ritchieng/the-incredible-pytorch)
- [ ] [MultiModal Machine Learning - C.M.U](https://cmu-multicomp-lab.github.io/mmml-course/fall2020/schedule/)
- [ ] [Multilingual Natural Language Processing](http://demo.clab.cs.cmu.edu/11737fa20/)
  - [X] [CMU Multilingual NLP 2020 (1): Introduction - `1:17:28`](https://www.youtube.com/watch?v=xeu7LKIT194&list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5&index=2&t=0s)
  - [X] [CMU Multilingual NLP 2020 (2): Typology - The Space of Language - `37:12`](https://www.youtube.com/watch?v=4QilRTLxvCc&list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5&index=2)
  - [X] [CMU Multilingual NLP 2020 (3): Words, Parts of Speech, Morphology - `38:57`](https://www.youtube.com/watch?v=kaSCjn7oMDw&list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5&index=3)
  - [X] [CMU Multilingual NLP 2020 (4): Text Classification and Sequence Labeling](https://www.youtube.com/watch?v=aDvI8-iE0pM&list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5&index=4)
  - [X] [CMU Multilingual NLP 2020 (5): Advanced Text Classification/Labeling - `49:39`](https://www.youtube.com/watch?v=aDvI8-iE0pM&list=PL8PYTP1V4I8CHhppU6n1Q9-04m96D9gt5&index=4)
- [ ] [CS 285: Deep Reinforcement Learning](https://www.youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc)
- [ ] [Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)
- [ ] [*Most* extensive list of "From Scratch Machine Learning".](https://github.com/eriklindernoren/ML-From-Scratch)

### Coding Tuts
- [ ] [Fine-tuning with custom datasets](https://huggingface.co/transformers/master/custom_datasets.html) & [Tweet](https://twitter.com/joeddav/status/1295361743322062848?s=20)
- [ ] [Easy GPT2 fine-tuning with @huggingface Transformers and @PyTorch using @GoogleColab](http://reyfarhan.com/posts/easy-gpt2-finetuning-huggingface/)
- [ ] [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate)
- [ ] [Deep dive into simCLR with code-first approach ("A Simple Framework for Contrastive Learning of Visual Representations")](https://www.youtube.com/playlist?list=PLaMu-SDt_RB4k8VXiB3hOdsn0Y3GoXo1k)
- [ ] [Python Knowledge Graph: Understanding Semantic Relationships](https://programmerbackpack.com/python-knowledge-graph-understanding-semantic-relationships/)
- [ ] [How to Get Started with Spark NLP in 2 Weeks](https://towardsdatascience.com/how-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d)
- [ ] [Training RoBERTa from scratch - the missing guide](https://zablo.net/blog/post/training-roberta-from-scratch-the-missing-guide-polish-language-model/?utm_source=twitter&utm_medium=link&utm_campaign=hf_stickers&utm_content=roberta-from-scratch)
- [X] [Building Multi Page Web App Using Streamlit](https://medium.com/@u.praneel.nihar/building-multi-page-web-app-using-streamlit-7a40d55fa5b4)
- [X] [Interactive Analysis of Sentence Embeddings](https://amitness.com/interactive-sentence-embeddings/)
- [ ] [Custom classifier on top of BERT-like Language Model - guide](https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/?utm_source=twitter&utm_medium=link&utm_campaign=hf_stickers&utm_content=classifier)
- [X] [Use @HelsinkiNLP's translation models transformers  to do very cheap back translators for data augmentation](https://discuss.huggingface.co/t/marian-language-discovery-questions/739/4?u=sshleifer)
- [ ] [Transformers' 1st-ever end-2-end multimodal demo - leveraging LXMERT, SOTA model for visual Q&A!](https://twitter.com/huggingface/status/1305517211159851008?s=20)
- [X] [`Video`: nbdev tutorial](https://www.youtube.com/watch?v=Hrs7iEYmRmg&feature=emb_title)
- [ ] [Fine-tune Transformers in PyTorch Using Hugging Face Transformers](https://www.linkedin.com/posts/philipvollet_deeplearning-pytorch-nlp-activity-6720947953479008256-4S5T/)
- [ ] [Comprehensive Language Model Fine Tuning, Part 1: 🤗 Datasets library - Normalizing](https://www.ntentional.com/nlp/datasets/tokenization/processing/2020/10/09/comprehensive-datasets.html)
- [X] [Building an entity extraction model using BERT](https://www.youtube.com/watch?v=MqQ7rqRllIc)
- [X] [`Implementation`: XLM-> HuggingFace Dataset & Model](https://huggingface.co/transformers/model_doc/xlm.html)
- [X] [`Implementation`: XLM-> HuggingFace Model & Loss](https://huggingface.co/transformers/model_doc/xlm.html)
- [X] [Spacy exploration]()
- [ ] [SparkNLP in 1 Hour](https://www.linkedin.com/posts/vkocaman_sparknlp-spark-tensorflow-activity-6715948330591031296-3tuA/)
- [X] [Ensembling, Blending & Stacking](https://www.youtube.com/watch?v=TuIgtitqJho)

### Events
- [X] [January 29th: 10PM IST/17:30 CET](https://eu.bbcollab.com/guest/38be8fe4cdcd40caab95c6ebb686c91e&sa=D&ust=1610987708425000&usg=AFQjCNFm2VET-mXrXsRSylyvY7FrmK6iTQ)

### Podcasts
- [X] [Aakash Nain | Tensorflow 2.0 | TF Add-Ons | Good API Designs | CTDS.Show #90](https://www.youtube.com/watch?v=hZNhkiIfHtM)
- [X] [Connor Shorten | Creating AI Content, Videos, | Henry AI Labs, Research & GANs | CTDS.Show #76](https://www.youtube.com/watch?v=Cn97ynuWAiQ)
- [ ] [Episode #191: Live from the Manning Python Conference](https://pythonbytes.fm/episodes/show/191/live-from-the-manning-python-conference)
- [ ] [TwiMLAI- Causal Modeling in ML](https://twitter.com/twimlai/status/1305129106175123456?s=03)

### Revisiting concepts with Survey Papers
- [ ] [Text Classification Algorithms: A Survey](https://arxiv.org/pdf/1904.08067.pdf)
- [ ] [A Survey of Evaluation Metrics Used for NLG Systems](https://arxiv.org/abs/2008.12009)
- [ ] [100 Must-Read NLP Papers](https://github.com/mhagiwara/100-nlp-papers)
- [ ] [A Survey of Surveys (NLP & ML)](https://github.com/NiuTrans/ABigSurvey)
- [ ] [Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732)
- [ ] [Towards MLOps: Technical capabilities of a Machine Learning platform](https://medium.com/prosus-ai-tech-blog/towards-mlops-technical-capabilities-of-a-machine-learning-platform-61f504e3e281)


### Blog ideas
- [X] [On Exploting LMs. Refer nlp-helper tool as well](https://gitlost-murali.github.io/blogs/blogs/nlp/exploiting-contextual-models-for-data)
- [ ] [Collate all - t5, marge, pegasus, electra etc.](https://github.com/freemiya)
- [X] [Explaining PDF backend](https://gitlost-murali.github.io/blogs/tooling/pdf/how-to-read-write-pdfs/)
- [X] [On label-studio usage and mapping with ML: Fast in a day or two](https://gitlost-murali.github.io/blogs/tooling/annotation/labelling-your-data/)
- [X] [Optimizing code & reducing runtime from 2+ hours to 8 mins](https://gitlost-murali.github.io/blogs/python/data-science/ml/runtime)
- [X] [On DVC](https://gitlost-murali.github.io/blogs/python/tooling/dvc)
- [ ] [`3/365` Shorts - HuggingFace GitLFS, Papermill, GPU dynamic select]()

### Financial & Career Knowledge
- [ ] [Finance]()
  - [ ] [Let's Talk money - `62%`]()
  - [ ] [The Psychology of Money](https://www.collaborativefund.com/blog/the-psychology-of-money/?s=03)
  - [X] [Recession Proofing My Tech Career _Or the Desi Guide to Personal Finance_](https://niranting.substack.com/p/recession-proofing-my-tech-career)
  - [ ] [Default Alive or Default Dead?](http://www.paulgraham.com/aord.html)
  - [X] [The FIRE movement](https://www.mrmoneymustache.com/2018/10/05/the-fire-movement/)
  - [X] [Prepping for the next Recession](https://www.mrmoneymustache.com/2017/06/20/next-recession/)
  - [X] [The Shockingly Simple Math Behind Early Retirement](https://www.mrmoneymustache.com/2012/01/13/the-shockingly-simple-math-behind-early-retirement/)
  - [X] [The 4% Rule: The Easy Answer to “How Much Do I Need for Retirement?”](https://www.mrmoneymustache.com/2012/05/29/how-much-do-i-need-for-retirement/)
  - [X] [Save Like A Pessimist, Invest Like An Optimist](https://www.collaborativefund.com/blog/save-like-a-pessimist-invest-like-an-optimist/)
  - [ ] [How to Prosper in an Economic Boom - For 2013, maynot be applicable now](https://www.mrmoneymustache.com/2013/05/07/how-to-prosper-in-an-economic-boom/)
  - [X] [Are You Cleaning Out Your Own Wallet?](https://www.mrmoneymustache.com/2013/12/30/are-you-cleaning-out-your-own-wallet/)
  - [X] [Getting out of the country, even within the same country: moving from Bengaluru to Varkala can be a huge income saver for most techies]()

- [ ] [Career]()
  - [ ] [Mentorship sessions to help students in research](https://mementor.net/#/)
  - [ ] [Free NLP assignments - Useful when teaching](https://openclass.ai/catalog/nlp)
  - [X] [Reflecting On My Failure To Craft Luck](https://pakodas.substack.com/p/reflecting-on-my-failure-to-craft?r=3w6vr&utm_campaign=post&utm_medium=web&utm_source=twitter)
  - [ ] [How to read and understand a scientific paper: a guide for non-scientists](https://blogs.lse.ac.uk/impactofsocialsciences/2016/05/09/how-to-read-and-understand-a-scientific-paper-a-guide-for-non-scientists/#8230)
  - [X] [How-to-Read-Papers-for-ideas](https://twitter.com/daniel_bilar/status/1305804091667484672?s=20)
  - [X] [Making Money, Making Happiness](https://www.nateliason.com/blog/making-money-making-happiness)
  - [X] [Decomplication: How to Find Simple Solutions to “Hard” Problems](https://www.nateliason.com/blog/decomplication)
  - [ ] [Level 3 Thinking: A Unified Theory of Self - Improvement](https://www.nateliason.com/blog/level-3-thinking)
  - [ ] [Real-time Machine Learning For Recommendations](https://eugeneyan.com/writing/real-time-recommendations/)
  - [ ] [What Machine Learning Can Teach Us About Life: 7 Lessons](https://eugeneyan.com/writing/life-lessons-from-machine-learning/)
  - [X] [Blog on writing everyday](https://medium.com/blankpage/what-happened-when-i-published-25-articles-in-one-month-790c541ada42)
  - [ ] [Offers 1:1 Career Advice calls](https://twitter.com/jesslynnrose/status/1300381984548679680)
  - [X] [You Don't Really Need Another MOOC](https://eugeneyan.com/writing/you-dont-need-another-mooc/)
  - [ ] [Useful vs. Useless Feedback](https://medium.com/swlh/useful-vs-useless-feedback-ba8c65cb7a4c)
  - [ ] [Masters/PhD application Advice by Andrew Trask -> Apply to work with a professor more than a dept/uni if possible ...](https://twitter.com/iamtrask/status/1303646976433623040?s=03)
  - [ ] [Compilation of resources for applications](https://twitter.com/996roma/status/1312356906388910080?s=20)
  - [ ] [Alexey Grigorev on His Career, Data Science, and Writing](https://eugeneyan.com/writing/informal-mentors-alexey-grigorev/)
  - [ ] [How Reading Papers Helps You Be a More Effective Data Scientist](https://eugeneyan.com/writing/why-read-papers/)
  - [ ] [The Effects of Sequence and Delay on Crowd Work](https://www.cs.cmu.edu/~jbigham/pubs/pdfs/2015/sequenceanddelay.pdf)
  - [X] [Chip Huyen: Four lessons I learned after my first full-time job after college](https://huyenchip.com/2019/12/23/leaving-nvidia-lessons.html)
  - [X] [Informal Mentors: Chip Huyen on Her Career, Writing, and ML](https://eugeneyan.com/writing/informal-mentors-chip-huyen/)
  - [ ] [NLP Trends and Use Cases in 2020](https://towardsdatascience.com/nlp-trends-and-use-cases-in-2020-dc8fb84a6e58)
  - [X] [Triple Thread : Career Advice](https://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html)
  - [X] [Standing Out at Work](https://niranting.substack.com/p/standing-out-at-work)
  - [X] [Where to go and why](https://pmarchive.com/guide_to_career_planning_part3.html)
  - [X] [Five Nonobvious Remote Work Techniques](https://queue.acm.org/detail.cfm?id=3417752&s=03)
  - [ ] [How to Accomplish More with Less - Useful Tools & Routines](https://eugeneyan.com/writing/how-to-accomplish-more-with-less/)
  - [X] [This Is The First 10 Years Of Your Career](https://m.huffpost.com/us/entry/us_58a99f03e4b0b0e1e0e20c40/amp?guccounter=1&__twitter_impression=true&s=03)
  - [ ] [Don't End The Week With Nothing](https://training.kalzumeus.com/newsletters/archive/do-not-end-the-week-with-nothing)
  - [X] [Act Like You're 35._What I wish I knew when I was 20 about Workplace_](https://niranting.substack.com/p/act-like-youre-35)
  - [ ] [Reach Out, Stay in Touch and Deepen Your Connections with This Essential Networking Advice](https://firstround.com/review/reach-out-stay-in-touch-and-deepen-your-connections-with-this-essential-networking-advice/)
  - [ ] [What happens if your job is automated en masse?](https://medium.com/@larissafschiavo/industrial-revolution-66aee1b2cc2d/)
  - [X] [5 Habits of Highly Effective Data Scientists](http://approximatelycorrect.com/2020/08/17/5-habits-of-highly-effective-data-scientists/)
  - [X] [Embrace Beginner's Mind; Avoid The Wrong Way To Be An Expert](https://eugeneyan.com/writing/beginners-mind/)
  - [ ] [Book: How to Deal with Bullies at Work - 13%](https://www.goodreads.com/book/show/33503509-the-asshole-survival-guide)
  - [ ] [Data Science and Agile (What works, and what doesn't)](https://eugeneyan.com/writing/data-science-and-agile-what-works-and-what-doesnt/)
  - [ ] [Why efficiency is dangerous and slowing down makes life better](https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better)
  - [X] [Unpopular Opinion - Data Scientists Should Be More End-to-End](https://eugeneyan.com/writing/end-to-end-data-science/)
  - [ ] [Tweet: On what an ML Engineer is expected to do](https://twitter.com/sh_reya/status/1295855995533524993?s=03)
  - [ ] [Research Statement from a FAIR candidate](https://twitter.com/dchaplot/status/1305590757974310918?s=20)
  - [ ] [A compilation of research advice(s) for doing good research and writing good papers.](https://github.com/TheShadow29/research-advice-list)

### Increase attention time & Dopamine
- [X] [Book: Riot](https://www.goodreads.com/book/show/30842.Riot)
- [ ] [Book: Stoicism - `78%`]()
- [ ] [Book: A Gentleman in Moscow - `9%`]()
- [ ] [Book: Why We Sleep? - `37%`]()
- [ ] [Book: The Psychology of Money - `24%`]()
- [ ] [Book: Into the Woods - `47%`]()
- [ ] [Book: No Country for Old Men - `12%`](https://www.goodreads.com/book/show/12497.No_Country_for_Old_Men)
- [X] [Book: Meditation and its methods - `49%` - Boring. Got the gist]()

### Writing

- [ ] [Daily writing sessions - 2]

### Datasets
- [ ] [TaxiNLI dataset - NLI example in the MultiNLI dataset with 18 features like Linguistic, Logic, Knowledge etc](https://github.com/microsoft/TaxiNLI)
- [ ] [Standardizing Indic NLP - Scripts for downloading various Indic NLP datasets and converting them into a standard format](https://github.com/deterministic-algorithms-lab/Std-Indic-NLP.git)
- [ ] [QED: A Framework and Dataset for Explanations in Question Answering](https://arxiv.org/abs/2009.06354)
- [ ] [Clinical NER datasets collection -> CADEC, ADE corpus, i2b2/n2c2 2018, MIMIC-3 & UK-CRIS](https://clinical-nlp.github.io/2020/resources.html)
- [ ] [Contract Understanding Atticus Dataset](https://github.com/TheAtticusProject/cuad/)

### (Deep) Learning with Limited Labeled Data (DL3D): Unsupervised, Self-Supervised Learning Papers
- [ ] [Twitter post mentioning major concepts in Limited-Data Setting](https://twitter.com/iskander/status/1292904556943286272?s=20)
- [ ] [Adaptive Name Entity Recognition under Highly Unbalanced Data](https://arxiv.org/pdf/2003.10296.pdf)

[Reference](https://github.com/craffel/dl3d-seminar)

| **Title** | **Approach** | **Domain** |
|---|---|---|
| [Semi-Supervised Learning with Deep Generative Models](https://arxiv.org/abs/1406.5298) | Semi-Supervised Learning | CV |
| [Learning and Transferring Mid-Level Image Representations using Convolutional Neural Networks](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf) | Transfer Learning | CV |
| [How transferable are features in deep neural networks?](https://arxiv.org/abs/1411.1792) | Transfer Learning | CV |
| [Skip-Thought Vectors](https://arxiv.org/abs/1506.06726) | Transfer/Representation Learning | NLP |
| [Semi-Supervised Sequence Learning](https://arxiv.org/abs/1511.01432) | Transfer Learning | NLP |
| [Learning Distributed Representations of Sentences from Unlabelled Data](https://arxiv.org/abs/1602.03483) | Transfer Learning | NLP |
| [Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725) | Semi-Supervised Learning | NLP |
| [Regularization With Stochastic Transformations and Perturbations for Deep Semi-Supervised Learning](https://arxiv.org/abs/1606.04586) | Semi-Supervised Learning | CV |
| [What makes ImageNet good for transfer learning?](https://arxiv.org/abs/1608.08614) | Transfer Learning | CV |
| [Temporal Ensembling for Semi-Supervised Learning](https://arxiv.org/abs/1610.02242) | Semi-Supervised Learning | CV |
| [Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning](https://arxiv.org/abs/1704.03976) | Semi-Supervised Learning | CV |
| [Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](https://arxiv.org/abs/1705.02364) | Transfer/Representation Learning | NLP |
| [Good Semi-supervised Learning that Requires a Bad GAN](https://arxiv.org/abs/1705.09783) | Semi-Supervised Learning | CV |
| [Snorkel: Rapid Training Data Creation with Weak Supervision](https://arxiv.org/abs/1711.10160) | Weak/Active Learning | Many |
| [~~Universal Language Model Fine-tuning for Text Classification~~](https://arxiv.org/abs/1801.06146) | Transfer Learning | NLP |
| [~~Deep Contextualized Word Representations~~](https://arxiv.org/abs/1802.05365) | Transfer Learning | NLP |
| [An efficient framework for learning sentence representations](https://arxiv.org/abs/1803.02893) | Transfer/Representation Learning | NLP |
| [Universal Sentence Encoder](https://arxiv.org/abs/1803.11175) | Transfer/Representation Learning | NLP |
| [Exploring the Limits of Weakly Supervised Pretraining](https://arxiv.org/abs/1805.00932) | Transfer Learning | CV |
| [Do Better ImageNet Models Transfer Better?](https://arxiv.org/abs/1805.08974) | Transfer Learning | CV |
| [Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) | Transfer Learning | NLP |
| [Understanding Back-Translation at Scale](https://arxiv.org/abs/1808.09381) | Semi-Supervised Learning | NLP |
| [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) | Transfer Learning | NLP |
| [Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks](https://arxiv.org/abs/1811.01088) | Transfer Learning | NLP |
| [Rethinking ImageNet Pre-Training](https://arxiv.org/abs/1811.08883) | Transfer Learning | CV |
| [Cross-lingual Language Model Pretraining](https://arxiv.org/abs/1901.07291) | Transfer Learning | NLP |
| [Multi-Task Deep Neural Networks for Natural Language Understanding](https://arxiv.org/abs/1901.11504) | Transfer Learning | NLP |
| [Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/abs/1902.00751) | Transfer Learning | NLP |
| [Task2Vec: Task Embedding for Meta-Learning](https://arxiv.org/abs/1902.03545) | Transfer Learning | CV |
| [To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks](https://arxiv.org/abs/1903.05987) | Transfer Learning | NLP |
| [Unsupervised Data Augmentation for Consistency Training](https://arxiv.org/abs/1904.12848) | Semi-Supervised Learning | CV + NLP |
| [Billion-scale semi-supervised learning for image classification](https://arxiv.org/abs/1905.00546) | Semi-Supervised Learning | CV |
| [MixMatch: A Holistic Approach to Semi-Supervised Learning](https://arxiv.org/abs/1905.02249) | Semi-Supervised Learning | CV |
| [MASS: Masked Sequence to Sequence Pre-training for Language Generation](https://arxiv.org/abs/1905.02450) | Transfer Learning | NLP |
| [Unified Language Model Pre-training for Natural Language Understanding and Generation](https://arxiv.org/abs/1905.03197) | Transfer Learning | NLP |
| [S4L: Self-Supervised Semi-Supervised Learning](https://arxiv.org/abs/1905.03670) | Semi-Supervised Learning | CV |
| [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/abs/1905.05583) | Transfer Learning | NLP |
| [Data-Efficient Image Recognition with Contrastive Predictive Coding](https://arxiv.org/abs/1905.09272) | Transfer/Representation Learning | CV |
| [Synthetic QA Corpora Generation with Roundtrip Consistency](https://arxiv.org/abs/1906.05416) | Semi-Supervised Learning | NLP |
| [~~XLNet: Generalized Autoregressive Pretraining for Language Understanding~~](https://arxiv.org/abs/1906.08237) | Transfer Learning | NLP |
| [Large Scale Adversarial Representation Learning](https://arxiv.org/abs/1907.02544) | Transfer/Representation Learning | CV |
| [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) | Transfer Learning | NLP |
| [Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning](https://arxiv.org/abs/1908.02983) | Semi-Supervised Learning | CV |
| [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.1194) | Transfer Learning | NLP |
| [Self-training with Noisy Student improves ImageNet classification](https://arxiv.org/abs/1911.04252) | Semi-Supervised Learning | CV |
| [Momentum Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/1911.05722) | Transfer/Representation Learning | CV |
| [Big Transfer (BiT): General Visual Representation Learning](https://arxiv.org/abs/1912.11370) | Transfer Learning | CV |
| [Semi-Supervised Learning with Normalizing Flows](https://arxiv.org/abs/1912.13025) | Semi-Supervised Learning | Many |
| [FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence](https://arxiv.org/abs/2001.07685) | Semi-Supervised Learning | CV |
| [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) | Transfer/Representation Learning | CV |
| [Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping](https://arxiv.org/abs/2002.06305) | Transfer Learning | NLP |
| [`3/9` ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://arxiv.org/abs/2003.10555) | Transfer Learning | NLP |
| [Rethinking Pre-training and Self-training](https://arxiv.org/abs/2006.06882) | Transfer and Semi-Supervised Learning | CV |
| [Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning](https://arxiv.org/abs/2006.07733) | Transfer/Representation Learning | CV |
| [Unsupervised Learning of Visual Features by Contrasting Cluster Assignments](https://arxiv.org/abs/2006.09882) | Transfer/Representation Learning | CV |
| [Big Self-Supervised Models are Strong Semi-Supervised Learners](https://arxiv.org/abs/2006.10029) | Semi-Supervised Learning | CV |
